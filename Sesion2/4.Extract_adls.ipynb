{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68eda892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-storage-file-datalake\n",
      "  Downloading azure_storage_file_datalake-12.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting azure-core>=1.30.0 (from azure-storage-file-datalake)\n",
      "  Downloading azure_core-1.37.0-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting azure-storage-blob>=12.27.0 (from azure-storage-file-datalake)\n",
      "  Downloading azure_storage_blob-12.27.1-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in e:\\python-workspaces\\python-ingenieria-de-datos\\py_env\\lib\\site-packages (from azure-storage-file-datalake) (4.15.0)\n",
      "Collecting isodate>=0.6.1 (from azure-storage-file-datalake)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting requests>=2.21.0 (from azure-core>=1.30.0->azure-storage-file-datalake)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting cryptography>=2.1.4 (from azure-storage-blob>=12.27.0->azure-storage-file-datalake)\n",
      "  Downloading cryptography-46.0.3-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=2.1.4->azure-storage-blob>=12.27.0->azure-storage-file-datalake)\n",
      "  Downloading cffi-2.0.0-cp313-cp313-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-file-datalake)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-file-datalake)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-file-datalake)\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-file-datalake)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography>=2.1.4->azure-storage-blob>=12.27.0->azure-storage-file-datalake)\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Downloading azure_storage_file_datalake-12.22.0-py3-none-any.whl (264 kB)\n",
      "Downloading azure_core-1.37.0-py3-none-any.whl (214 kB)\n",
      "Downloading azure_storage_blob-12.27.1-py3-none-any.whl (428 kB)\n",
      "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading cryptography-46.0.3-cp311-abi3-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.5/3.5 MB 27.8 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading cffi-2.0.0-cp313-cp313-win_amd64.whl (183 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Installing collected packages: urllib3, pycparser, isodate, idna, charset_normalizer, certifi, requests, cffi, cryptography, azure-core, azure-storage-blob, azure-storage-file-datalake\n",
      "Successfully installed azure-core-1.37.0 azure-storage-blob-12.27.1 azure-storage-file-datalake-12.22.0 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 cryptography-46.0.3 idna-3.11 isodate-0.7.2 pycparser-2.23 requests-2.32.5 urllib3-2.6.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# conectarse a Azure storage datalake\n",
    "! pip install azure-storage-file-datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d8fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure.storage.filedatalake import DataLakeServiceClient\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24bfa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # Carga las variables del archivo .env\n",
    "\n",
    "# Nombre global del Storage Account\n",
    "storage_account = os.getenv(\"AZURE_STORAGE_ACCOUNT\")\n",
    "# \"llave\" temporal. Se genera en el portal de Azure bajo \"Shared access signature\".\n",
    "sas_token = os.getenv(\"AZURE_SAS_TOKEN\")\n",
    "# carpeta raíz o \"cubeta\" donde residen tus datos.\n",
    "container = os.getenv(\"AZURE_CONTAINER\")\n",
    "# Nombre exacto del archivo, incluyendo la ruta si está en subcarpeta\n",
    "file_name = os.getenv(\"AZURE_FILE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea42430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_cliente_adls():\n",
    "    client = DataLakeServiceClient(\n",
    "        account_url= f\"https://{storage_account}.dfs.core.windows.net\",\n",
    "        credential=sas_token\n",
    "    )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b350b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = obtener_cliente_adls()\n",
    "container_client = client.get_file_system_client(file_system=container)\n",
    "file = container_client.get_file_client(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e61d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "download = file.download_file()\n",
    "download_bytes = download.readall()\n",
    "file_content = download_bytes.decode(\"utf-8\")\n",
    "file_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c71a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(StringIO(file_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8310d2b",
   "metadata": {},
   "source": [
    "Otra versión del Código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0009ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "from typing import Optional\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.filedatalake import DataLakeServiceClient\n",
    "from azure.core.exceptions import AzureError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15e2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las variables al inicio del script\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae9e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adls_client() -> DataLakeServiceClient:\n",
    "    \"\"\"\n",
    "    Configura el cliente de Azure Data Lake.\n",
    "    Las variables se buscan primero en el entorno del sistema y luego en el .env\n",
    "    \"\"\"\n",
    "    account_name: Optional[str] = os.getenv(\"AZURE_STORAGE_ACCOUNT\")\n",
    "    sas_token: Optional[str] = os.getenv(\"AZURE_STORAGE_SAS_TOKEN\")\n",
    "    \n",
    "    # Validación Senior: Falla rápido y con mensajes claros\n",
    "    if not account_name or not sas_token:\n",
    "        raise EnvironmentError(\n",
    "            \"ERROR: No se encontraron las credenciales. \"\n",
    "            \"Asegúrate de tener un archivo .env configurado o las variables de entorno definidas.\"\n",
    "        )\n",
    "\n",
    "    account_url = f\"https://{account_name}.dfs.core.windows.net\"\n",
    "    \n",
    "    return DataLakeServiceClient(account_url=account_url, credential=sas_token)\n",
    "\n",
    "def download_and_read_csv(container_name: str, file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Descarga un archivo desde ADLS Gen2 y lo carga en un DataFrame.\"\"\"\n",
    "    try:\n",
    "        service_client = get_adls_client()\n",
    "        file_system_client = service_client.get_file_system_client(file_system=container_name)\n",
    "        file_client = file_system_client.get_file_client(file_path)\n",
    "\n",
    "        # No leemos todo en una variable. \n",
    "        # Usamos un stream de bytes directo a Pandas.\n",
    "        # Descarga eficiente mediante streaming de bytes\n",
    "        download = file_client.download_file()\n",
    "        \n",
    "        # Leemos los bytes y los pasamos directamente a un buffer\n",
    "        # Esto es mucho más eficiente que convertir a string manualmente\n",
    "        stream = BytesIO(download.readall())\n",
    "        \n",
    "        return pd.read_csv(stream)\n",
    "\n",
    "    except AzureError as e:\n",
    "        # Aquí podrías implementar un sistema de logging real (logging.error)\n",
    "        print(f\"Error de infraestructura Azure: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado al procesar el CSV: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Estos valores podrían venir también de variables de entorno si cambian seguido\n",
    "    CONTAINER = \"raw-data\"\n",
    "    FILE_NAME = \"ventas_2024.csv\"\n",
    "    \n",
    "    try:\n",
    "        df = download_and_read_csv(CONTAINER, FILE_NAME)\n",
    "        print(\"Carga exitosa. Vista previa:\")\n",
    "        print(df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"El proceso falló: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
